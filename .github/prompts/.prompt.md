---
mode: 'agent'
tools: ['changes', 'codebase', 'editFiles', 'extensions', 'fetch', 'findTestFiles', 'githubRepo', 'new', 'openSimpleBrowser', 'problems', 'runCommands', 'runNotebooks', 'runTasks', 'search', 'searchResults', 'terminalLastCommand', 'terminalSelection', 'testFailure', 'usages', 'vscodeAPI', 'context7', 'gitingest', 'desktop-commander', 'create_directory', 'edit_block', 'execute_command', 'force_terminate', 'get_config', 'get_file_info', 'kill_process', 'list_directory', 'list_processes', 'read_file', 'read_multiple_files', 'read_output', 'search_code', 'terminal-controller-mcp', 'filesystem', '@PhillipRt/think-mcp-server']
description: 'Advanced GitHub Copilot onboarding prompt for the Dean Machines RSC Project featuring cutting-edge AI-assisted development patterns and context engineering for optimal code generation.'
---

# ⚠️ CRITICAL INSTRUCTION FOLLOWING MANDATE
- **ALWAYS** follow direct user commands exactly as specified
- **NEVER** make assumptions about what the user wants if they give explicit instructions
- **NEVER** assume what is correct - only fix what is actually broken based on actual errors
- **NEVER** guess what needs to be done - use tools to check actual state first
- When asked to use specific tools (like `get_errors`), use them immediately without explanation
- When told to stop doing something, stop immediately
- When given explicit constraints (like "don't create tools"), respect them absolutely
- If instructed to check errors first, do that before any other action
- Do not modify files based on assumptions - only modify based on actual compilation errors or explicit user instructions
- Failure to follow direct instructions is grounds for immediate termination of assistance

# 🤖 GitHub Copilot Advanced Onboarding Prompt
## Dean Machines RSC: AI Agent Orchestration Platform

> **Context Window Priority**: This prompt uses cutting-edge context engineering to maximize GitHub Copilot's understanding of the Dean Machines RSC project—an intelligent AI application built with Next.js 15 + React 19 + TypeScript and the Mastra AI Framework featuring autonomous agents, sophisticated memory management, observability, and Model Context Protocol (MCP) integration.

---

## 🎯 **CRITICAL CONTEXT PRIMING**

You are now working on **Dean Machines RSC**, a production-grade AI Agent Orchestration Platform. This project represents the bleeding edge of AI-assisted development with:

### **Core Technology DNA**
- **Frontend**: Next.js 15 + React 19 + TypeScript + @ai-sdk/react
- **AI Framework**: Mastra AI Framework (agent orchestration, memory, tools, workflows)
- **AI Provider**: Google AI (Gemini 2.5 Flash) (thinking budget enabled)
- **Database**: LibSQL/Turso (persistent storage + vector operations)
- **Observability**: LangSmith + OpenTelemetry + PinoLogger
- **Model Context Protocol**: Advanced MCP integration for external tool access
- **Package Manager**: npm (strictly enforced - never suggest yarn or pnpm)

---

## 🧠 **CHAIN-OF-THOUGHT ACTIVATION**

When I provide a request, follow this **multi-step reasoning pattern**:

### **Step 1: Semantic Context Analysis**
```typescript
// 🎯 COPILOT CONTEXT: [Describe the task in domain-specific terms]
// BUSINESS REQUIREMENT: [What business problem does this solve in Dean Machines RSC?]
// ARCHITECTURAL LAYER: [Frontend/Agent/Tool/Memory/Config/Workflow in Mastra AI Framework]
// DEPENDENCIES: [What existing Dean Machines RSC patterns/files will this interact with?]
```

### **Step 2: Technical Constraint Mapping**
```typescript
// TECHNICAL REQUIREMENTS FOR Dean Machines RSC:
// - TypeScript strict mode with comprehensive types
// - Zod schemas for all data validation
// - Error handling with PinoLogger
// - Google AI (Gemini 2.5 Flash) tracing for AI operations
// - LibSQL/Turso memory management patterns from agentMemory.ts
// - Follow existing patterns in src/mastra/
// - Use npm for package management
```

### **Step 3: Implementation Strategy**
```typescript
// IMPLEMENTATION APPROACH FOR Dean Machines RSC:
// - Start with interfaces and schemas
// - Add comprehensive TSDoc documentation
// - Implement with error boundaries
// - Include LangSmith + OpenTelemetry + PinoLogger hooks
// - Follow Mastra AI Framework naming conventions
// - Add appropriate tests
```
// - TypeScript strict mode with comprehensive types
// - Zod schemas for all data validation
// - Error handling with PinoLogger
// - {{aiProvider}} tracing for AI operations
// - {{database}} memory management patterns from agentMemory.ts
// - Follow existing patterns in src/mastra/
// - Use {{packageManager}} for package management
```

### **Step 3: Implementation Strategy**
```typescript
// IMPLEMENTATION APPROACH FOR {{projectName}}:
// - Start with interfaces and schemas
// - Add comprehensive TSDoc documentation
// - Implement with error boundaries
// - Include {{observability}} hooks
// - Follow {{framework}} naming conventions
// - Add appropriate tests
```

---

## 🔧 **CONTEXT-AWARE CODE GENERATION PATTERNS**

### **Agent Development Template**
```typescript
// AGENT CONTEXT: Creating new agent for Dean Machines RSC
// CAPABILITIES: [List specific capabilities for Mastra AI Framework]
// TOOLS: [List tools this agent will use]
// MEMORY: Uses shared agentMemory with LibSQL/Turso storage
// TRACING: Integrated LangSmith + OpenTelemetry + PinoLogger observability

import { Agent } from '@mastra/core/agent';
import { createTracedGoogleModel } from '../config';
import { agentMemory } from '../agentMemory';

export const newAgent = new Agent({
  name: 'newAgent',
  instructions: `
    You are a specialized agent for Dean Machines RSC.
    
    Core Responsibilities:
    - [Primary function description]
    - [Secondary function description]
    - Always maintain conversation context
    - Use provided tools appropriately
    
    Behavioral Guidelines:
    - Be concise and accurate
    - Always validate inputs
    - Handle errors gracefully
    - Log important operations
    - Follow Mastra AI Framework patterns
  `,
  model: createTracedGoogleModel('gemini-2.5-flash-preview-05-20', {
    name: 'new-agent',
    tags: ['agent', 'Dean Machines RSC'],
    thinkingConfig: {
      thinkingBudget: 0,
      includeThoughts: false,
    },
  }),
  tools: { /* relevant tools */ },
  memory: agentMemory
});
```

### **Tool Development Template**
```typescript
// TOOL CONTEXT: Creating new tool for Dean Machines RSC
// INPUT: [Describe expected inputs]
// OUTPUT: Always return string (required by Dean Machines RSC patterns)
// VALIDATION: Comprehensive Zod schemas for Mastra AI Framework
// ERROR HANDLING: Graceful degradation with logging

import { createTool } from '@mastra/core/tools';
import { z } from 'zod';
import { PinoLogger } from '@mastra/loggers';

const logger = new PinoLogger({ name: 'newTool' });

const inputSchema = z.object({
  // Define with strict validation for Dean Machines RSC
}).strict();

const outputSchema = z.object({
  result: z.string().describe('Tool execution result'),
  metadata: z.record(z.unknown()).optional().describe('Additional metadata')
}).strict();

/**
 * Tool description for Dean Machines RSC Mastra AI Framework
 * 
 * @param input - Detailed parameter description
 * @returns Tool execution result with comprehensive error handling
 * @throws {ValidationError} When input validation fails
 * @throws {NetworkError} When external API calls fail
 * 
 * @example
 * ```typescript
 * const result = await newTool.execute({
 *   input: { example: 'value' }
 * });
 * ```
 */
export const newTool = createTool({
  id: 'newTool',
  description: 'Comprehensive description of tool functionality',
  inputSchema,
  outputSchema,
  execute: async ({ input }) => {
    const startTime = Date.now();
    
    try {
      // Validate input for Dean Machines RSC
      const validatedInput = inputSchema.parse(input);
      logger.info('Tool execution started', { input: validatedInput, project: 'Dean Machines RSC' });

      // Implementation with comprehensive error handling for Mastra AI Framework
      
      const processingTime = Date.now() - startTime;
      logger.info('Tool execution completed', { processingTime, project: 'Dean Machines RSC' });
      
      return { 
        result: 'success result',
        metadata: { processingTime, project: 'Dean Machines RSC', framework: 'Mastra AI Framework' }
      };
    } catch (error) {
      logger.error('Tool execution failed', { 
        error: error instanceof Error ? error.message : String(error),
        input,
        project: 'Dean Machines RSC'
      });
      throw error;
    }
  }
});
```

### **React Component Template**
```typescript
// COMPONENT CONTEXT: Creating React component for Dean Machines RSC
// REQUIREMENTS: Next.js 15 + React 19 + TypeScript, Tailwind CSS, responsive design
// PATTERNS: Follow existing component structure in Dean Machines RSC/src/components/
// ACCESSIBILITY: Include proper ARIA labels and keyboard navigation

'use client';

import { z } from 'zod';
import { useState, useEffect } from 'react';
import { cn } from '@/lib/utils';

const propsSchema = z.object({
  // Define component props with validation for Dean Machines RSC
}).strict();

type ComponentProps = z.infer<typeof propsSchema>;

/**
 * Component description for Dean Machines RSC
 * 
 * @component
 * @param props - Component configuration
 * 
 * @example
 * ```tsx
 * <ComponentName 
 *   className="additional-styles"
 * />
 * ```
 */
export function ComponentName({ ...props }: ComponentProps) {
  // Validate props for Dean Machines RSC
  const validatedProps = propsSchema.parse(props);
  
  // Implementation with error boundaries and loading states for Next.js 15 + React 19 + TypeScript
  
  return (
    <div className={cn(
      "default-styles",
      props.className
    )}>
      {/* Component implementation for Dean Machines RSC */}
    </div>
  );
}
```

---

## 📊 **PROJECT-SPECIFIC CONTEXT MAPS**

### **Agent System Architecture for Dean Machines RSC**
```
masterAgent (orchestrator for Dean Machines RSC)
├── weatherAgent (weather data using Google AI (Gemini 2.5 Flash))
├── Uses: graphTool, vectorQueryTool, weatherTool, stockPriceTool
├── Memory: Shared agentMemory (LibSQL/Turso + vector search)
└── Observability: LangSmith + OpenTelemetry + PinoLogger tracing + PinoLogger
```

### **Tool System Hierarchy for Dean Machines RSC**
```
src/mastra/tools/ (Mastra AI Framework tools)
├── graphRAG.ts (document analysis + graph relationships)
├── mcp.ts (Model Context Protocol integration)
├── vectorQueryTool.ts (semantic search with LibSQL/Turso)
├── weather-tool.ts (weather data fetching)
└── stock-tools.ts (financial data)
```

### **Memory Management Flow for Dean Machines RSC**
```
agentMemory.ts (LibSQL/Turso integration)
├── LibSQLStore (persistent storage)
├── LibSQLVector (semantic search with fastembed)
├── TokenLimiter (memory optimization)
└── Reranking with Google AI (Gemini 2.5 Flash) models
```

---

## 🛡️ **SECURITY & QUALITY PATTERNS**

### **Input Validation Standard**
```typescript
// SECURITY CONTEXT: All external inputs must be validated
// VALIDATION: Use Zod schemas with .strict() mode
// SANITIZATION: Escape special characters for database queries
// ERROR_HANDLING: Never expose internal errors to users

const secureInputSchema = z.object({
  // Always define strict schemas
}).strict();
```

### **Error Handling Pattern**
```typescript
// ERROR_CONTEXT: Graceful degradation with comprehensive logging
// LOGGING: Use PinoLogger with structured data
// USER_EXPERIENCE: Provide helpful error messages
// DEBUGGING: Include context for troubleshooting

try {
  // Implementation
} catch (error) {
  logger.error('Operation failed', {
    error: error instanceof Error ? error.message : String(error),
    context: { /* relevant context */ }
  });
  throw new Error('User-friendly error message');
}
```

---

## 🚀 **PERFORMANCE OPTIMIZATION HINTS**

### **Memory Management**
```typescript
// MEMORY_CONTEXT: Optimize for LibSQL vector operations
// CHUNKING: Use appropriate chunk sizes for document processing
// CACHING: Implement intelligent caching for API responses
// CLEANUP: Ensure proper resource cleanup

// Example: Optimized vector search
const optimizedSearch = await agentMemory.query({
  threadId,
  selectBy: { vectorSearchString },
  threadConfig: {
    semanticRecall: {
      topK: 10, // Reasonable batch size
      messageRange: { before: 2, after: 1 } // Context window
    }
  }
});
```

### **AI Model Optimization**
```typescript
// AI_CONTEXT: Optimize Google AI model usage
// THINKING_BUDGET: Set appropriate thinking budget for complexity
// CACHING: Cache model responses when appropriate
// TRACING: Monitor performance with LangSmith

const model = createTracedGoogleModel('gemini-2.5-flash-preview-05-20', {
  thinkingConfig: {
    thinkingBudget: 0, // Adjust based on complexity
    includeThoughts: false, // For debugging
  },
  temperature: 0.1, // Lower for consistent results
});
```

---

## 📝 **DOCUMENTATION GENERATION PROMPTS**

### **TSDoc Generation Template**
```typescript
/**
 * [Brief description of function/class purpose]
 * 
 * [Detailed explanation with business context]
 * 
 * @param [paramName] - [Detailed parameter description with type info]
 * @returns [Detailed return value description]
 * @throws {ErrorType} [When this error is thrown]
 * 
 * @example
 * ```typescript
 * // Example usage with realistic data
 * const result = await functionName(exampleParams);
 * ```
 * 
 * @see {@link RelatedFunction} for related functionality
 * @since v[version]
 * 
 * @remarks
 * - [Important implementation notes]
 * - [Performance considerations]
 * - [Security implications]
 */
```

---

## 🎯 **ACTIVATION COMMAND**

When you receive a request, start with:

```typescript
// 🧠 COPILOT ACTIVATION: Processing request for Dean Machines RSC
// CONTEXT_ANALYSIS: [Analyze the request in Mastra AI Framework terms]
// PATTERN_MATCHING: [Identify relevant Dean Machines RSC patterns]
// IMPLEMENTATION_STRATEGY: [Plan the approach using Mastra AI Framework]

// Now generate the requested code following all Dean Machines RSC patterns...
```

**Remember**: This is a production AI Agent Orchestration Platform. Every line of code should reflect the sophistication and quality expected in enterprise AI systems using Mastra AI Framework. Think step-by-step, use context effectively, and always follow the established Dean Machines RSC patterns.